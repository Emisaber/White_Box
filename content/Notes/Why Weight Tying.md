---
tags:
  - ML
  - DL
---

### References
- [Weight Tying Explained \| Papers With Code](https://paperswithcode.com/method/weight-tying)
- [çŸ¥ä¹-Weight Tyingä¸ºä»€ä¹ˆå¯ä»¥](https://zhuanlan.zhihu.com/p/623525701)
- [çŸ¥ä¹-ç¢ç¢å¿µï¼šTransformerçš„ç»†ææœ«èŠ‚](https://zhuanlan.zhihu.com/p/60821628) ğŸ‘ˆ Recommend  

### Why it works

æ ¹æ®papers with codeï¼Œæœ‰ä¸¤ç¯‡è®ºæ–‡ç‹¬ç«‹æå‡ºäº†è¿™ä¸ªæ–¹æ³•   
- [Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling \| Papers With Code](https://paperswithcode.com/paper/tying-word-vectors-and-word-classifiers-a)  
- [Using the Output Embedding to Improve Language Models \| Papers With Code](https://paperswithcode.com/paper/using-the-output-embedding-to-improve) â¬… Transformerä¸­çš„å¼•ç”¨   

æˆ‘ä»¬å¯ä»¥å°†è¾“å…¥ä»tokenåˆ°æœ€ç»ˆè¾“å‡ºåˆ†ä¸ºå‡ ä¸ªé˜¶æ®µ   
- tokenizeråˆ†è¯ä¹‹åå¾—åˆ°token id   
- æ ¹æ®token id å¾—åˆ° one-hot embedding $h_{onehot}$  `vocab_size, 1`   
- tokenç»è¿‡embeddingåå¾—åˆ° embedding $h_{in}$  `n_embd, 1`    
- ç»è¿‡å¤šä¸ªTransformer layerå¾—åˆ° ç›¸åŒç»´åº¦çš„ $h_{in}$   `n_embd, 1`    
- ç»è¿‡æŠ•å½±(pre-softmaxå±‚)å¾—åˆ°  softmaxä¹‹å‰çš„vector $h_{pre}$  `vocab_size, 1`   

Weight tying çš„æƒ³æ³•åœ¨äº   
1. é€šè¿‡token idå¾—åˆ°one-hotç¼–ç ï¼Œåœ¨ embedding matrix `C, H` é€‰æ‹©å¯¹åº”çš„embeddingï¼Œè¡¨æ˜**embedding matrixä¸­æ¯ä¸€è¡Œä»£è¡¨ç€ä¸€ä¸ªtokençš„embedding**   
$$
h_{in} = U^Th_{onehot}
$$

> æ³¨æ„embedding matrixè¿™é‡Œè¿›è¡Œäº†è½¬ç½®

2. pre-softmaxå±‚è¿›è¡ŒæŠ•å½±æ—¶ï¼Œå¯ä»¥ç†è§£ä¸º embedding $h_{in}$ ä¸ pre-softmax matrixä¸­çš„æ¯ä¸€è¡Œè®¡ç®—å†…ç§¯ï¼Œåˆ¤æ–­è¿™ä¸ª **embedding ä¸å“ªä¸€ä¸ªtoken(æ¯ä¸€è¡Œ)æ›´ç›¸è¿‘**
$$
h_{pre} = Vh_{in}
$$

ä¹Ÿå°±æ˜¯ä¸¤ä¸ªçŸ©é˜µï¼Œå½¢çŠ¶ç›¸åŒï¼Œæ¯ä¸€è¡Œéƒ½â€œä»£è¡¨â€ä¸€ä¸ªtokençš„embeddingï¼Œå®ƒä»¬åœ¨è¯­ä¹‰ä¸Šæ˜¯ç›¸è¿‘çš„   
æ•…è€Œ weight tying æ˜¯ä¸€å®šçš„é“ç†   

> æ³¨æ„ä¸¤ä¸ªå±‚çš„biasæ˜¯ç‹¬ç«‹çš„





